{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning using the Flickr8k Dataset\n",
    "Keras-built neural network trained on the Flickr8k Dataset. When given an image, the model is able to output an image caption describing it.\n",
    "\n",
    "Since each image has multiple captions corresponding to it, we'll be using an approach called multi-caption training in which we create multiple training examples for each image, where each example pairs the image with one of its corresponding captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Preprocessing\n",
    "from tensorflow.keras.utils import img_to_array, load_img, to_categorical, pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Layers\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, Embedding, LSTM, Bidirectional, add\n",
    ")\n",
    "\n",
    "# Misc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our image data is stored in the `flickr8k/Images` directory in this repository and our captions are stored in `flickr8k/captions.txt`. Let's read the captions and create a map from the filenames to the captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A black dog and a spotted dog are fighting',\n",
       " 'A black dog and a tri-colored dog playing with each other on the road .',\n",
       " 'A black dog and a white dog with brown spots are staring at each other in the street .',\n",
       " 'Two dogs of different breeds looking at each other on the road .',\n",
       " 'Two dogs on pavement moving toward each other .']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data.\n",
    "df = pd.read_csv('data/captions.txt', header=0, delimiter=',', names=['image', 'caption'])\n",
    "\n",
    "# Create a map of image to captions.\n",
    "captions = df.groupby('image')['caption'].apply(list).to_dict()\n",
    "\n",
    "# Display a random image and its captions.\n",
    "captions[\"1001773457_577c3a7d70.jpg\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Preprocessing\n",
    "First we need to preprocess the labels, cleaning them out and converting them into vectors of integers. Here, we clear out unnecessary characters and make each word lowercase. We also add each caption to an array called `all_captions` that we can pass into a Keras tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>a black dog and a spotted dog are fighting<end>',\n",
       " '<start>a black dog and a tri-colored dog playing with each other on the road .<end>',\n",
       " '<start>a black dog and a white dog with brown spots are staring at each other in the street .<end>',\n",
       " '<start>two dogs of different breeds looking at each other on the road .<end>',\n",
       " '<start>two dogs on pavement moving toward each other .<end>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of all the captions.\n",
    "all_captions = []\n",
    "\n",
    "# Iterate over all the filenames.\n",
    "for filename, img_captions in captions.items():\n",
    "    # Iterate over each caption for the specific file.\n",
    "    for i, caption in enumerate(img_captions):\n",
    "        # Convert the caption to lowercase.\n",
    "        caption = caption.lower()\n",
    "\n",
    "        # Remove all the special characters.\n",
    "        caption = caption.replace(\"[^a-z]+\", \"\")\n",
    "\n",
    "        # Remove all additional spaces.\n",
    "        caption = caption.replace(\"\\s+\", \" \")\n",
    "\n",
    "        # Add starting and ending tokens.\n",
    "        caption = f\"<start>{caption}<end>\"\n",
    "\n",
    "        # Update the caption.\n",
    "        img_captions[i] = caption\n",
    "\n",
    "        # Append the caption to the list of all captions.\n",
    "        all_captions.append(caption)\n",
    "\n",
    "# Display the updated caption.\n",
    "captions[\"1001773457_577c3a7d70.jpg\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to use the Keras `Tokenizer` to tokenize the text, essentially transforming it into a sequence of numbers. This is a result of the fact that neural networks are only able to process and output information when they are in the form of Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 1, 15, 9, 8, 1, 842, 9, 17, 343, 2],\n",
       " [3, 1, 15, 9, 8, 1, 1574, 235, 9, 34, 10, 137, 82, 6, 5, 151, 2],\n",
       " [3, 1, 15, 9, 8, 1, 14, 9, 10, 27, 1000, 17, 640, 22, 137, 82, 4, 5, 72, 2],\n",
       " [3, 13, 31, 12, 740, 2651, 89, 22, 137, 82, 6, 5, 151, 2],\n",
       " [3, 13, 31, 6, 726, 804, 321, 137, 82, 2]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial the tokenizer. Don't set the num_words parameter.\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on the captions.\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "\n",
    "# Iterate over all of the files.\n",
    "for filename in captions.keys():\n",
    "    # Replace the raw text captions with the sequences.\n",
    "    captions[filename] = tokenizer.texts_to_sequences(captions[filename])\n",
    "\n",
    "# Store the size of the vocabulary.\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Display the first few captions.\n",
    "captions[\"1001773457_577c3a7d70.jpg\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "Now that we've done some basic setting up of the labels, it's time to focus on images. We first will download the `MobileNetV2` pre-trained convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 22:13:47.797305: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-26 22:13:47.797540: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         1281000     ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,538,984\n",
      "Trainable params: 3,504,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_net = MobileNetV2(weights='imagenet', include_top=True)\n",
    "image_net.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've installed the pre-trained model, we need to create our own model that utilizes it. Our goal is to only extract the features of the image from the pre-trained CNN, which will enable us to train our model on the features of the image rather than the raw image data. This is far more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to extract features from the images.\n",
    "model = Model(inputs=image_net.input, outputs=image_net.layers[-2].output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined this model, we're going to create a dictionary that maps from image/filenames to the respective features outputted by the `MobileNetV2` model. We do this because we'll be training the model on the same input features multiple times (but slightly different input labels). This will make a little more sense later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8091 [00:00<?, ?it/s]2023-03-26 22:13:48.901421: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-26 22:13:49.134810: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|██████████| 8091/8091 [04:26<00:00, 30.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map the image name to the features.\n",
    "image_features = {}\n",
    "\n",
    "# Iterate over all the images.\n",
    "for filename in tqdm(captions.keys()):\n",
    "    #Load our images in the target size of 224x224.\n",
    "    img = load_img(f\"./data/Images/{filename}\", target_size=(224, 224))\n",
    "\n",
    "    # Vectorize the image.\n",
    "    x = img_to_array(img)\n",
    "\n",
    "    # Expand the dimensions of the image.\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "    # Calculate the flattened features array.\n",
    "    features = model.predict(x, verbose=0)\n",
    "    features = np.reshape(features, (features.shape[1]))\n",
    "    \n",
    "    # Store the features array.\n",
    "    image_features[filename] = features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split\n",
    "Now that we've preprocessed all of our data, it's time to split it up in preparation for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 1091)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate our data into training and testing data.\n",
    "# 7000 training images and 1091 test images.\n",
    "train_images = list(captions.keys())[:7000]\n",
    "test_images = list(captions.keys())[7000:]\n",
    "\n",
    "len(train_images), len(test_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Instances\n",
    "Now that we've set pretty everything up, we need to create \"training instances\". In order to understand what we're doing, we first need to look into how the model will work.\n",
    "\n",
    "The model, when given an image, will generate a text sequence, but it is only able to generate a single word at a time. This means that to generate the entire text sequence, 1) we'll need to repeatedly call the `model.predict` method, and 2) the model will need two input layers. One input layer will represent the image data and the second one will be the text sequence.\n",
    "\n",
    "Due to this, we'll need to create multiple training instances for each caption. Each one will represent the same image data, but the captions for each word will contain the incremented sequence. \n",
    "\n",
    "For example, say we have an image with the caption: `<start> a big fat cat <end>`. We would have 6 different instances:\n",
    "```\n",
    "<start>\n",
    "<start> a\n",
    "<start> a big\n",
    "<start> a big fat\n",
    "<start> a big fat cat\n",
    "<start> a big fat cat <end>\n",
    "```\n",
    "\n",
    "This will train the model to generate more accurate captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [00:01<00:00, 3860.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x arrays done\n",
      "y array done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((413035, 1280), (413035, 38), (413035, 8494))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the maximum length of a description in a dataset\n",
    "maxlen = max(len(caption.split()) for caption in all_captions)\n",
    "\n",
    "# Create three empty arrays.\n",
    "# One for image inputs, one for caption inputs, and the final one for full labels.\n",
    "x_img, x_caption, y = [], [], []\n",
    "\n",
    "# Iterate over each training image.\n",
    "for filename in tqdm(train_images):\n",
    "    # Retrieve the image features.\n",
    "    image = image_features[filename]\n",
    "\n",
    "    # Iterate over each caption \n",
    "    for sequence in captions[filename]:\n",
    "        # Iterate over each value (word) in the sequence.\n",
    "        # We skip the first word in the sequence because that's just the start code.\n",
    "        for i in range(1, len(sequence)):\n",
    "            # Our input value will be the sequence up until point `i`.\n",
    "            # We also right-pad the sequence to the maximum length.\n",
    "            input_sequence = sequence[:i]\n",
    "            input_sequence = pad_sequences([input_sequence], maxlen=maxlen)[0]\n",
    "\n",
    "            # Our output sequence is simply the next word.\n",
    "            output_sequence = sequence[i]\n",
    "\n",
    "            # Append the data to the arrays.\n",
    "            x_img.append(image)\n",
    "            x_caption.append(input_sequence)\n",
    "            y.append(output_sequence)\n",
    "\n",
    "# Convert the arrays to numpy arrays.\n",
    "x_img = np.array(x_img)\n",
    "x_caption = np.array(x_caption)\n",
    "\n",
    "# Log that we're done with the x arrays.\n",
    "print(\"x arrays done\")\n",
    "\n",
    "# Create an empty array for the output labels.\n",
    "labels = np.zeros((len(y), vocab_size))\n",
    "\n",
    "# Iterate over the output labels.\n",
    "for i, label in enumerate(y):\n",
    "    # Convert the label to a one-hot vector.\n",
    "    labels[i] = to_categorical([label], num_classes=vocab_size)[0]\n",
    "\n",
    "# Log that we're done with the y array.\n",
    "print(\"y array done\")\n",
    "\n",
    "\n",
    "# Output the shapes of the arrays.\n",
    "x_img.shape, x_caption.shape, labels.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our Model\n",
    "Now comes to fun part: defining our model! \n",
    "\n",
    "The model will follow an encoder-decoder architecture, which is perfect for sequence to sequence models like this one. An encoder-decoder model consists of two main components, an encoder and a decoder. First, the encoder is used to encode the input sequence into a feature vector, which, second, the decoder will use to generate the output sequence.\n",
    "\n",
    "We've actually already partially defined the encoder in this model: the (pre-trained) CNN, which takes our image, and \"encodes\" it by extracting the features of the image. Our CNN outputs a 2048-dimension vector (so a vector with a length of 2048).\n",
    "\n",
    "The decoder is an LSTM (Long-Short Term Memory) RNN that processes the partial image caption and then generates the next word based on the features of the image. Our decoder uses two LSTM layers, with one being bidirectional, the model is able to capture more information and learn more complex betters in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our image input and the feature encoding layers to process it.\n",
    "image_input = Input(shape=(1280,))                                              # 1280 is the size of the flattened features array.\n",
    "dropout_1 = Dropout(0.2)(image_input)                                           # Dropout layer to prevent overfitting.\n",
    "dense_1 = Dense(256, activation='relu')(dropout_1)                              # Dense layer to reduce the size of the features array.\n",
    "\n",
    "# Define our caption input and the sequence encoding layers to process it.\n",
    "caption_input = Input(shape=(maxlen,))                                          # The maximum length of a caption.\n",
    "embedding = Embedding(vocab_size, 200, mask_zero=True)(caption_input)  # Embedding layer to convert the words to vectors.\n",
    "dropout_2 = Dropout(0.2)(embedding)                                             # Dropout layer to prevent overfitting.\n",
    "\n",
    "# Now we'll define the LSTM layers to process the encoded caption sequence.\n",
    "lstm_1 = Bidirectional(LSTM(256, return_sequences=True))(dropout_2)             # LSTM layer to process the sequence.\n",
    "lstm_2 = LSTM(256)(lstm_1)                                                      # LSTM layer to process the sequence.\n",
    "\n",
    "# Combine the image and caption inputs.\n",
    "decoder_1 = add([dense_1, lstm_2])                                              # Add the image and caption inputs.\n",
    "decoder_2 = Dense(256, activation='relu')(decoder_1)                            # Dense layer to reduce the size of the features array.\n",
    "\n",
    "# We'll use a softmax activation function to predict the next word.\n",
    "output = Dense(vocab_size, activation='softmax')(decoder_2)             # Dense layer that outputs prediction for the next word.\n",
    "\n",
    "# Define the model. We have two inputs for the image and caption, and one output for the prediction.\n",
    "model = Model(inputs=[image_input, caption_input], outputs=output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that embedding layer? We can actually define the weights for that using GloVe, a pre-trained unsupervised learning algorithm for obtaining vector representations for words. We've loaded the weight values for that data in the `glove` directory. \n",
    "\n",
    "You can download it [here](https://www.kaggle.com/datasets/rtatman/glove-global-vectors-for-word-representation?select=glove.6B.200d.txt).\n",
    "\n",
    "We're going to retrieve all necessary words from GloVe and replace our embedding layer's weights with the outputs from GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty numpy array that we will eventually replace the Embedding layer weights with.\n",
    "embedding_matrix = np.zeros((vocab_size, 200))\n",
    "\n",
    "# Create a dictionary to map the words to their GloVe vectors.\n",
    "embedding_dict = {}\n",
    "\n",
    "# Open the file containing the GloVe vectors.\n",
    "with open(\"./data/glove.6B.200d.txt\", \"r\") as glove:\n",
    "    # Retrieve each line in the file.\n",
    "    values = glove.readlines()\n",
    "\n",
    "    # Iterate over each line.\n",
    "    for value in values:\n",
    "        # Retrieve the word.\n",
    "        word = value.split()[0]\n",
    "\n",
    "        # Continue if the word is not in our tokenizer.\n",
    "        if word not in tokenizer.word_index:\n",
    "            continue\n",
    "\n",
    "        # Retrieve the vector. Note that we skip the first value because it's the word.\n",
    "        vector = np.array(value.split()[1:], dtype=\"float32\")\n",
    "\n",
    "        # Store the vector in the dictionary.\n",
    "        embedding_dict[word] = vector\n",
    "\n",
    "# Iterate over each word in the tokenizer.\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    # Retrieve the vector for the word.\n",
    "    vector = embedding_dict.get(word)\n",
    "\n",
    "    # If the word has a vector, store it in the embedding matrix.\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i] = vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our embedding matrix, we can replace the weights of the model's Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.embedding.Embedding object at 0x2b86263b0>\n"
     ]
    }
   ],
   "source": [
    "# Our embedding layer is the second layer in the model.\n",
    "print(model.layers[1])\n",
    "\n",
    "# Replace the weights of the embedding layer with our embedding matrix.\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "\n",
    "# Freeze the weights of the embedding layer.\n",
    "model.layers[1].trainable = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to compile our model. We'll be using the `adam` optimizer and `categorical_crossentropy`. \n",
    "\n",
    "The `adam` optimizer is a good choice as it is computationally efficient and requires little memory, making it suitable for large-scale problems like image captioning. \n",
    "\n",
    "The `categorical_crossentropy` is often used for multi-class classificaiton problems. Although this model generates a text sequence, at each time step, it predicts the next word in the caption using a one-hot encoded representation, which technically is classification. Categorical cross-entropy loss will measure the dissimilarity between the predicted probability distribution and the true distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to fit the model using thirty epochs. We'll "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 22:23:10.845643: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12908/12908 [==============================] - 1966s 152ms/step - loss: 3.9814\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "# Set the CPU as the device to train on.\n",
    "with tf.device(\"/cpu:0\"):\n",
    "\n",
    "    # Iterate over 30 epochs.\n",
    "    for i in range(30):\n",
    "\n",
    "        # Train the model.\n",
    "        model.fit([x_img, x_caption], labels, epochs = 1, batch_size = 32, verbose = 1)\n",
    "\n",
    "        # Save the model weights every 2 epochs.\n",
    "        if(i%2 == 0):\n",
    "            model.save_weights(\"image-caption-weights\" + str(i) + \".h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
